---
authors:
  - Charles Rathkopf
  - Bert Heinrichs
author_notes:
  - "First author. Jülich Research Center, University of Bonn"
  - "Second author. Jülich Research Center, University of Bonn"
publication_short: Cambridge Quarterly of Healthcare Ethics 
abstract: Position papers on AI ethics are often framed as attempts to work out technical and regulatory strategies for attaining what is commonly called trustworthy AI. In such papers, the technical and regulatory strategies are frequently analyzed in detail, but the concept of trustworthy AI is not. As a result, it remains unclear. This paper lays out a variety of possible interpretations of the concept and concludes that none of them is appropriate. The central problem is that, by framing the ethics of AI in terms of trustworthiness, we reinforce unjustified anthropocentric assumptions that stand in the way of clear analysis. Furthermore, even if we insist on a purely epistemic interpretation of the concept, according to which trustworthiness just means measurable reliability, it turns out that the analysis will, nevertheless, suffer from a subtle form of anthropocentrism. The paper goes on to develop the concept of strange error, which serves both to sharpen the initial diagnosis of the inadequacy of trustworthy AI, and to articulate the novel epistemological situation created by the use of AI. The paper concludes with a discussion of how strange error puts pressure on standard practices of assessing moral culpability, especially in the context of medicine. 
projects:
share: false
summary: Where ML models are used as the centerpiece of an epistemic classification procedure, reliability is not sufficient for ethical use. The nature of classification errors should be taken into account. 
url_project: ""
publication: ""
date: false
title: "Strange error: Beyond trustworthiness in AI ethics"
publishDate: 
url_poster: ""
url_code: ""
doi: ""
---




